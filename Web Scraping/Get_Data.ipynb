{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e4f73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b9627",
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cd3bf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASONS = list(range(2016,2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "384ea6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2016, 2017, 2018, 2019, 2020, 2021, 2022]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEASONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7375260",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=\"data\"\n",
    "STANDINGS_DIR =os.path.join(DATA_DIR,\"standings\")\n",
    "SCORES_DIR=os.path.join(DATA_DIR,\"scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ddf258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an asynchronous function to fetch HTML content from a web page\n",
    "async def get_html(url, selector, sleep=5, retries=3):\n",
    "    # Initialize the HTML content to None\n",
    "    html = None\n",
    "    # Loop through the specified number of retries\n",
    "    for i in range(1, retries+1):\n",
    "        # Wait for a specified number of seconds before retrying (the wait time increases with each retry)\n",
    "        time.sleep(sleep * i)\n",
    "        try:\n",
    "            # Create a new instance of Playwright\n",
    "            async with async_playwright() as p:\n",
    "                # Launch a new Chromium browser\n",
    "                browser = await p.chromium.launch()\n",
    "                # Create a new page in the browser\n",
    "                page = await browser.new_page()\n",
    "                # Navigate to the specified URL\n",
    "                await page.goto(url)\n",
    "                # Print the title of the page (for debugging purposes)\n",
    "                print(await page.title())\n",
    "                # Extract the HTML content using the specified CSS selector\n",
    "                html = await page.inner_html(selector)\n",
    "        except PlaywrightTimeout:\n",
    "            # If a timeout occurs, print an error message and continue to the next iteration of the loop\n",
    "            print(f\"Timeout error on {url}\")\n",
    "            continue\n",
    "        else:\n",
    "            # If the HTML content is successfully extracted, break out of the loop and return the HTML content\n",
    "            break\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "season = 2016 \n",
    "url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games-november.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654389ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38d3a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games-november.html\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    links = [a.get(\"href\") for a in soup.select(\"#content .filter a\")]\n",
    "    print(links)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29399ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "standing_pages=[f\"https://www.basketball-reference.com{l}\" for l in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5caccc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "standing_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c52e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in standing_pages :\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        table = soup.select_one(\"#all_schedule\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "    save_path = os.path.join(STANDINGS_DIR,url.split('/')[-1])\n",
    "    if os.path.exists(save_path):\n",
    "        continue\n",
    "\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(str(table)) \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55300a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_standings_pages(season):\n",
    "    \"\"\"\n",
    "    Fetches and saves the standings pages for the given NBA season.\n",
    "\n",
    "    Args:\n",
    "        season (str): the NBA season (in the format \"YYYY-ZZ\", e.g. \"2021-22\")\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch the links to the standings pages for the given NBA season\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games-november.html\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        links = [a.get(\"href\") for a in soup.select(\"#content .filter a\")]\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return\n",
    "\n",
    "    # Fetch and save the HTML content of each standings page\n",
    "    for link in links:\n",
    "        url = f\"https://www.basketball-reference.com{link}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            table = soup.select_one(\"#all_schedule\")\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        save_path = os.path.join(STANDINGS_DIR, link.split(\"/\")[-1])\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "\n",
    "        with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(str(table))\n",
    "\n",
    "    print(f\"All standings pages for {season} have been fetched and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e812c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_standings_pages(2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a84095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All standings pages for 2016 have been fetched and saved.\n",
      "All standings pages for 2017 have been fetched and saved.\n",
      "All standings pages for 2018 have been fetched and saved.\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n",
      "All standings pages for 2019 have been fetched and saved.\n",
      "Error: 429\n",
      "Error: 429\n",
      "Error: 429\n"
     ]
    }
   ],
   "source": [
    "for season in SEASONS :\n",
    "    fetch_standings_pages(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "075390cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "standings_files=os.listdir(STANDINGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92390891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NBA_2016_games-april.html',\n",
       " 'NBA_2016_games-december.html',\n",
       " 'NBA_2016_games-february.html',\n",
       " 'NBA_2016_games-january.html',\n",
       " 'NBA_2016_games-june.html',\n",
       " 'NBA_2016_games-march.html',\n",
       " 'NBA_2016_games-may.html',\n",
       " 'NBA_2016_games-november.html',\n",
       " 'NBA_2016_games-october.html',\n",
       " 'NBA_2017_games-april.html',\n",
       " 'NBA_2017_games-december.html',\n",
       " 'NBA_2017_games-february.html',\n",
       " 'NBA_2017_games-january.html',\n",
       " 'NBA_2017_games-june.html',\n",
       " 'NBA_2017_games-march.html',\n",
       " 'NBA_2017_games-may.html',\n",
       " 'NBA_2017_games-november.html',\n",
       " 'NBA_2017_games-october.html',\n",
       " 'NBA_2018_games-april.html',\n",
       " 'NBA_2018_games-december.html',\n",
       " 'NBA_2018_games-february.html',\n",
       " 'NBA_2018_games-january.html',\n",
       " 'NBA_2018_games-june.html',\n",
       " 'NBA_2018_games-march.html',\n",
       " 'NBA_2018_games-may.html',\n",
       " 'NBA_2018_games-november.html',\n",
       " 'NBA_2018_games-october.html',\n",
       " 'NBA_2019_games-december.html',\n",
       " 'NBA_2019_games-february.html',\n",
       " 'NBA_2019_games-january.html',\n",
       " 'NBA_2019_games-march.html',\n",
       " 'NBA_2019_games-november.html',\n",
       " 'NBA_2019_games-october.html']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standings_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24d51703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_game(standings_file):\n",
    "    with open(standings_file,'r') as f :\n",
    "        html=f.read()\n",
    "    soup=BeautifulSoup(html)\n",
    "    links=soup.find_all('a')\n",
    "    hrefs=[l.get(\"href\") for l in links]\n",
    "    box_scores=[l for l in hrefs if l and \"boxscore\" in l and '.html' in l ]\n",
    "    box_scores=[f\"https://www.basketball-reference.com{l}\" for l in box_scores]\n",
    "    for url in box_scores:\n",
    "        save_path = os.path.join(SCORES_DIR,url.split(\"/\")[-1])\n",
    "        if os.path.exists (save_path):\n",
    "            continue\n",
    "        html = soup.select_one(\"#content\")\n",
    "        if not html :\n",
    "            continue\n",
    "        with open(save_path,\"w+\")as f:\n",
    "            f.write(str(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56fab873",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [s for s in standings_files if str(season) in s ]\n",
    "for f in files :\n",
    "    filepath = os.path.join(STANDINGS_DIR,f)\n",
    "    scrape_game(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e292266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e479410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835353b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2071a0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
